{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "about-heavy",
   "metadata": {},
   "source": [
    "## 0. Libarary 불러오기 및 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029d4596-d270-4449-a707-7745f80f21d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wandb\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from PIL import Image \n",
    "from torchvision import models\n",
    "from resnest.torch import resnest50\n",
    "import timm\n",
    "\n",
    "os.chdir('/opt/ml')\n",
    "from utils.Dataset import Class18Dataset, cfg, get_img_paths\n",
    "from utils.utils import calculate_norm, linear_param_initialize, train_mean_std\n",
    "import torch.utils.data as data\n",
    "from tqdm.notebook import tqdm\n",
    "from train import train\n",
    "from baseline.loss import FocalLoss, LabelSmoothingLoss, F1Loss\n",
    "import warnings\n",
    "from model.model import ThreeOneNet, Resnest50\n",
    "from utils.utils import eval_mean_std\n",
    "from baseline.dataset_mike import MaskBaseDataset, MyCrop\n",
    "from model.Ensemble_model.baty import baty_model\n",
    "from model.Ensemble_model.mike import mike_model\n",
    "from model.Ensemble_model.peachy import peachy_model\n",
    "from baseline.dataset_v2 import MaskBaseDataset, MyCrop, MyCropMid, MyCropDown, Ensemble\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "built-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = '/opt/ml/input/data/eval'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-organizer",
   "metadata": {},
   "source": [
    "## 1. Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b3a051-80ec-4cbc-bf4a-29ec16e2c710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mike_model1 = mike_model.get_model(2)\n",
    "mike_model2 = mike_model.get_model(2)\n",
    "mike_model3 = mike_model.get_model(2)\n",
    "\n",
    "\n",
    "mike_model1.load_state_dict(torch.load('/opt/ml/model/Ensemble_model/mike/2.pt'))\n",
    "mike_model2.load_state_dict(torch.load('/opt/ml/model/Ensemble_model/mike/1.pt'))\n",
    "mike_model3.load_state_dict(torch.load('/opt/ml/model/Ensemble_model/mike/0.pt'))\n",
    "\n",
    "\n",
    "baty_model4 = baty_model.Resnext50()\n",
    "baty_model5 = baty_model.Resnext50()\n",
    "\n",
    "                                             \n",
    "baty_model4.load_state_dict(torch.load('/opt/ml/model/Ensemble_model/baty/best3.pth'))\n",
    "baty_model5.load_state_dict(torch.load('/opt/ml/model/Ensemble_model/baty/last.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-channels",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Test Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extensive-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-feelings",
   "metadata": {},
   "source": [
    "## 3. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "510d413a-3f73-412e-93b0-42cfefe284d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coral-shade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=126.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                    MyCrop(),\n",
    "                    transforms.Resize((370,324),Image.BILINEAR),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Grayscale(3)\n",
    "                    ])\n",
    "\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "model1 = mike_model1.cuda()\n",
    "model2 = mike_model2.cuda()\n",
    "model3 = mike_model3.cuda()\n",
    "\n",
    "model4 = baty_model4.cuda()\n",
    "model5 = baty_model5.cuda()\n",
    "\n",
    "\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "model4.eval()\n",
    "model5.eval()\n",
    "\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions1 = []\n",
    "for images in tqdm(loader, leave=False):\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model1(images) + model2(images) + model3(images) + model4(images) + model5(images)\n",
    "        pred =pred.argmax(dim=-1)\n",
    "    all_predictions1.extend(pred.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "904bde14-dcbf-4878-b988-2b5c20d95331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "submission['ans'] = all_predictions1\n",
    "submission.to_csv(os.path.join('/opt/ml/submission', 'submission-(baty3,last + mike0,1,2.csv)-nosoftmax-최종.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6449388a-7671-4408-8461-86d541783afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions1[6473]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0121daa-892c-419d-8fa1-4c258110b8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "1,3 제외"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
